package ch1;

public class FirstPointTwo {
    public static void main(String[] args) {
        String bigDataTec = "Spark的分布式内存处理框架的出现,提出了将数据切分成微批的处理模式进行流式数据处理,从而能够在一套计算框架内完成批量计算和流式计算\n" +
                ",但是因为spark本身是基于批处理模式的原因,并不能完美且高效地处理原生的数据流,因此对流式计算支持的相对较弱,可以说spark的出现的本质上是在\n" +
                "一定程度上对Hadoop架构进行了一定的升级和优化.";
        String stateCal = "数据产生的本质,其实是一条条真实存在的事件,前面提到的不同的架构其实都是在一定程度违背了这种本质,需要通过在一定延时的情况下对业务数据进行处理\n" +
                ",然后得到基于业务数据统计的准确结果.实际上,基于流式计算技术局限性,我们很难在数据产生的过程中进行计算并直接产生统计结果,因为这不仅对系统\n" +
                "有非常高的要求,还必须要满足高性能、高吞吐、低延时等众多目标.\n" +
                "而有状态流计算框架的提出,从一定程度上满足了企业的这种需求,企业基于实时的流式数据,维护所有计算过程的状态,所谓状态就是计算过程中产生的中间结果\n" +
                ",每次计算新的数据进入到流式系统中都是基于中间状态结果的基础上进行运算,最终产生正确的统计结果. 基于有状态的计算的方式最大的优势是不需要\n" +
                "将原始数据重新从外部存储中拿出来,从而进行全量计算,因为这种计算方式的代价可能是非常高的. 从另一个角度讲,用户无须通过调度和协调各种批量计算工具,\n " +
                "从数据仓库中获取数据统计结果,然后再落地存储,这些操作全部都可以基于流式计算完成,可以极大地减轻系统对其他框架的依赖,减少数据计算过程中的时间损耗一级硬件\n" +
                "存储. 如果计算的结果能保持一致,实时计算在很短的时间内统计出结果,批量计算则需要等待一定时间才能得出,相信大多数用户会更加倾向于选择使用有状态流进行大数据处理.\n";
        String whyChoseFlink = "" +
                "1. 同时支持高吞吐、低延迟、高性能\n" +
                "2. 支持事件时间(Event Time)概念\n" +
                "3. 支持有状态计算\n" +
                "4. 支持高度灵活的窗口(Window)操作\n" +
                "5. 基于轻量级分布式快照(Snapshot)实现的容错\n" +
                "6. 基于JVM实现独立的内存管理\n" +
                "7. Save Points(保存点)";

        System.out.println(bigDataTec);
        System.out.println(stateCal);
        System.out.println(whyChoseFlink);
    }
}
